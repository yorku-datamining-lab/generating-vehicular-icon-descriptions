{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Icon, Dataset\n",
    "from llm import GPT, Claude, Llava\n",
    "\n",
    "import openai\n",
    "import anthropic\n",
    "from ollama import Client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# import evaluate\n",
    "# import pandas as pd\n",
    "\n",
    "# from bert_score import BERTScorer\n",
    "# from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets from Saved Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset(\"\")\n",
    "train.load_pkl(\"k-shot_train.pkl\")\n",
    "\n",
    "test = Dataset(\"\")\n",
    "test.load_pkl(\"k-shot_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 388\n"
     ]
    }
   ],
   "source": [
    "print(len(train.icons), len(test.icons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Do Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset(\"\")\n",
    "# dataset.load_pkl(\"ground-truth.pkl\")\n",
    "# dataset.name = \"all manuals - multi-ground-truth - k-shot\"\n",
    "# train, test = dataset.split_train_test(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(train.icons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(test.icons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.save_pkl(\"train.pkl\")\n",
    "# test.save_pkl(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # API keys are stored in an environment variable\n",
    "openai_client = openai.OpenAI()\n",
    "anth_client = anthropic.Anthropic()\n",
    "llava_client = Client() # pass host=<ollama_api_endpoint> if necessary\n",
    "\n",
    "INSTRUCTIONS = (\n",
    "    \"You are an AI visual assistant specialized in interpreting icons displayed on the dashboard of a vehicle. \"\n",
    "    \"An icon communicates important information about the vehicle to the driver. \"\n",
    "    \"For example, a particular icon may indicate that a seatbelt is not fastened. \"\n",
    "    \"You are seeing an image of a single dashboard icon. \"\n",
    ")\n",
    "PROMPT = (\n",
    "    \"Briefly describe the dashboard icon depicted in the image, focusing on the visual content of the image and meaning of the icon. \"\n",
    "    \"Limit your response to 2 sentences. The first sentence should describe the visual content. The second sentence should describe the icon's meaning.\"\n",
    "    \"Format your response as a JSON object with the following keys: 'visual_content', 'meaning'. \"\n",
    "    \"Respond only with the JSON object. \"\n",
    "    \"The image has the following associated text: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o, Claude 3.5, LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(openai_client, \"gpt-4o\")\n",
    "claude = Claude(anth_client, \"claude-3-5-sonnet-20240620\")\n",
    "llava = Llava(llava_client, \"llava:34b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment #1: k=0,1,3,5 (Image + Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in [0]:\n",
    "for k in [0, 5, 1, 3]:\n",
    "    gpt.get_captions(\n",
    "        train = train,\n",
    "        test = test,\n",
    "        k = k,\n",
    "        treatment = f\"gpt-4_k-{k}_closest\",\n",
    "        instructions = INSTRUCTIONS,\n",
    "        prompt = PROMPT,\n",
    "        use_image = True,\n",
    "        use_context = True,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    # test.save_pkl(\"k-shot.pkl\")\n",
    "    test.save_json(\"../outputs/temp-k-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InternalServerError: Error code: 500 - {'type': 'error', 'error': {'type': 'api_error', 'message': 'Internal server error'}}\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 3, 5]:\n",
    "    claude.get_captions(\n",
    "        train = train,\n",
    "        test = test,\n",
    "        k = k,\n",
    "        treatment = f\"claude-3-5_k-{k}_closest\",\n",
    "        instructions = INSTRUCTIONS,\n",
    "        prompt = PROMPT,\n",
    "        use_image = True,\n",
    "        use_context = True,\n",
    "        max_tokens=1000,\n",
    "        rerun=True\n",
    "    )\n",
    "    test.save_pkl(\"k-shot_test.pkl\")\n",
    "    test.save_json(\"../outputs/k-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [0, 5, 1, 3]:\n",
    "    llava.get_captions(\n",
    "        train = train,\n",
    "        test = test,\n",
    "        k = k,\n",
    "        treatment = f\"llava_k-{k}_closest\",\n",
    "        instructions = INSTRUCTIONS,\n",
    "        prompt = PROMPT,\n",
    "        use_image = True,\n",
    "        use_context = True,\n",
    "        max_tokens=1000    \n",
    "    )\n",
    "    # test.save_pkl(\"k-shot.pkl\")\n",
    "    test.save_json(\"../outputs/temp-k-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.save_json(\"../outputs/k-shot_test.json\")\n",
    "test.save_pkl(\"k-shot_test.pkl\")\n",
    "\n",
    "train.save_json(\"../outputs/k-shot_train.json\")\n",
    "train.save_pkl(\"k-shot_train.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
