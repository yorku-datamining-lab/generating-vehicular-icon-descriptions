{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Icon, Dataset\n",
    "from llm import GPT, Claude, Llava\n",
    "\n",
    "import openai\n",
    "import anthropic\n",
    "from ollama import Client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# import evaluate\n",
    "# import pandas as pd\n",
    "\n",
    "# from bert_score import BERTScorer\n",
    "# from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets from Saved Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"\")\n",
    "dataset.load_pkl(\"ablation_zero-shot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.icons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_json(\"../outputs/zero-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_pkl(\"ablation_zero-shot.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o, Claude 3.5, LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # API keys are stored in an environment variable\n",
    "openai_client = openai.OpenAI()\n",
    "anth_client = anthropic.Anthropic()\n",
    "llava_client = Client() # pass host=<ollama_api_endpoint> if necessary\n",
    "\n",
    "gpt = GPT(openai_client, \"gpt-4o\")\n",
    "claude = Claude(anth_client, \"claude-3-5-sonnet-20240620\")\n",
    "llava = Llava(llava_client, \"llava:34b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREATMENTS = {\n",
    "    \"image-and-context\": [\n",
    "        (\"You are an AI visual assistant specialized in interpreting icons displayed on the dashboard of a vehicle. \"\n",
    "        \"An icon communicates important information about the vehicle to the driver. \"\n",
    "        \"For example, a particular icon may indicate that a seatbelt is not fastened. \"\n",
    "        \"You are seeing an image of a single dashboard icon. \"),\n",
    "        (\"Briefly describe the dashboard icon depicted in the image, focusing on the visual content of the image and meaning of the icon. \"\n",
    "        \"Limit your response to 2 sentences. The first sentence should describe the visual content. The second sentence should describe the icon's meaning.\"\n",
    "        \"Format your response as a JSON object with the following keys: 'visual_content', 'meaning'. \"\n",
    "        \"Respond only with the JSON object. \"\n",
    "        \"The image has the following associated text: \"),\n",
    "        True,\n",
    "        True\n",
    "    ], \n",
    "    \"image-only\": [\n",
    "        (\"You are an AI visual assistant specialized in interpreting icons displayed on the dashboard of a vehicle. \"\n",
    "        \"An icon communicates important information about the vehicle to the driver. \"\n",
    "        \"For example, a particular icon may indicate that a seatbelt is not fastened. \"\n",
    "        \"You are seeing an image of a single dashboard icon. \"),\n",
    "        (\"Briefly describe the dashboard icon depicted in the image, focusing on the visual content of the image and meaning of the icon. \"\n",
    "        \"Limit your response to 2 sentences. The first sentence should describe the visual content. The second sentence should describe the icon's meaning.\"\n",
    "        \"Format your response as a JSON object with the following keys: 'visual_content', 'meaning'. \"\n",
    "        \"Respond only with the JSON object. \"),\n",
    "        True,\n",
    "        False\n",
    "    ], \n",
    "    \"context-only\": [\n",
    "        (\"You are an AI visual assistant specialized in interpreting icons displayed on the dashboard of a vehicle. \"\n",
    "        \"An icon communicates important information about the vehicle to the driver. \"\n",
    "        \"For example, a particular icon may indicate that a seatbelt is not fastened. \"\n",
    "        \"Imagine you are seeing an image of a single dashboard icon that has an associated text description. \"),\n",
    "        (\"Briefly describe the dashboard icon depicted in the image, focusing on the visual content of the image and meaning of the icon. \"\n",
    "        \"Limit your response to 2 sentences. The first sentence should describe the visual content. The second sentence should describe the icon's meaning.\"\n",
    "        \"Format your response as a JSON object with the following keys: 'visual_content', 'meaning'. \"\n",
    "        \"Respond only with the JSON object. \"\n",
    "        \"The image has the following associated text: \"),\n",
    "        False,\n",
    "        True        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment #1: k=0,1,3,5 (Image + Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treatment, p in TREATMENTS.items():\n",
    "    instructions, prompt, use_image, use_context = p\n",
    "    gpt.get_captions(\n",
    "        train = None,\n",
    "        test = dataset,\n",
    "        k = 0,\n",
    "        treatment = f\"gpt-4_{treatment}\",\n",
    "        instructions = instructions,\n",
    "        prompt = prompt,\n",
    "        use_image = use_image,\n",
    "        use_context = use_context,\n",
    "        max_tokens=1000,\n",
    "        rerun=True\n",
    "    )\n",
    "    dataset.save_pkl(\"ablation_zero-shot.pkl\")\n",
    "    dataset.save_json(\"../outputs/zero-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treatment, p in TREATMENTS.items():\n",
    "    instructions, prompt, use_image, use_context = p\n",
    "    llava.get_captions(\n",
    "        train = None,\n",
    "        test = dataset,\n",
    "        k = 0,\n",
    "        treatment = f\"llava_{treatment}\",\n",
    "        instructions = instructions,\n",
    "        prompt = prompt,\n",
    "        use_image = use_image,\n",
    "        use_context = use_context,\n",
    "        max_tokens=1000,\n",
    "        rerun=True\n",
    "    )\n",
    "    dataset.save_pkl(\"ablation_zero-shot.pkl\")\n",
    "    dataset.save_json(\"../outputs/zero-shot.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for treatment, p in TREATMENTS.items():\n",
    "    instructions, prompt, use_image, use_context = p\n",
    "    claude.get_captions(\n",
    "        train = None,\n",
    "        test = dataset,\n",
    "        k = 0,\n",
    "        treatment = f\"claude-3-5_{treatment}\",\n",
    "        instructions = instructions,\n",
    "        prompt = prompt,\n",
    "        use_image = use_image,\n",
    "        use_context = use_context,\n",
    "        max_tokens=1000,\n",
    "        rerun=True\n",
    "    )\n",
    "    dataset.save_pkl(\"ablation_zero-shot.pkl\")\n",
    "    dataset.save_json(\"../outputs/zero-shot.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
